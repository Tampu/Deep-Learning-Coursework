{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKMJaxNdLgaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b0367ce9-3c1b-46d7-ba70-e4d05e6dee99"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "import keras.layers as layers\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0] , 'test samples')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gTqCyriLs_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f13f850e-fb48-48d7-e778-734c8a138eba"
      },
      "source": [
        "n_classes = 10\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "# cifar10 is RGB image, thus the last dimension, channel size will be 3\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "input_shape = img_rows, img_cols, 3\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test  = X_test.astype('float32')\n",
        "\n",
        "# images takes values between 0 - 255, we can normalize it\n",
        "# by dividing every number by 255\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('train shape:', X_train.shape)\n",
        "\n",
        "# one-hot encode the class (target) vectors\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test , n_classes)\n",
        "print('y_train shape:', Y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RijPWv7eMIwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\" \n",
        "    A block that has a conv layer at shortcut.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor:\n",
        "    \n",
        "    kernel_size: int\n",
        "        The kernel size of middle conv layer at main path.\n",
        "\n",
        "    filters: list[int]\n",
        "        The filters of 3 conv layer at main path.\n",
        "\n",
        "    stage: int\n",
        "        Current stage label, used for generating layer names.\n",
        "\n",
        "    block: : str\n",
        "        'a','b'..., current block label, used for generating layer names.\n",
        "        \n",
        "    strides : tuple, default (2, 2)\n",
        "        Strides for the first conv layer in the block.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Output tensor for the block.\n",
        "    \"\"\"\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # for batch normalization layer, we assume\n",
        "    # the input data is in channel last format,\n",
        "    # which is the case if we are using the default\n",
        "    # keras' backend tensorflow\n",
        "    bn_axis = 3\n",
        "\n",
        "    filters1, filters2, filters3 = filters\n",
        "  \n",
        "    # main path, note that setting the kernel_initializer set here is only used\n",
        "    # for reproducibility, we techniqually don't need it\n",
        "    x = layers.Conv2D(filters1, kernel_size=(1, 1), strides=strides,\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \n",
        "    # we resize the input so its dimension will match the output dimension\n",
        "    # of the main path\n",
        "    shortcut = layers.Conv2D(filters3, kernel_size=(1, 1), strides=strides,\n",
        "                             kernel_initializer=glorot_uniform(seed=0),\n",
        "                             padding='valid', name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut) \n",
        "\n",
        "    # this line is the core component of resnet, the skip connection, i.e.\n",
        "    # having a shortcut to the main path before the activation\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZwgCTLOMawR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\" \n",
        "    An identity block.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor:\n",
        "\n",
        "    kernel_size: int\n",
        "        The kernel size of middle conv layer at main path.\n",
        "\n",
        "    filters: list[int]\n",
        "        The filters of 3 conv layer at main path.\n",
        "\n",
        "    stage: int\n",
        "        Current stage label, used for generating layer names.\n",
        "\n",
        "    block: : str\n",
        "        'a','b'..., current block label, used for generating layer names.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Output tensor for the block.\n",
        "    \"\"\"\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # for batch normalization layer, we assume\n",
        "    # the input data is in channel last format\n",
        "    bn_axis = 3\n",
        "\n",
        "    filters1, filters2, filters3 = filters\n",
        "  \n",
        "    # main path, note that setting the kernel_initializer seed here is only used\n",
        "    # for reproducibility, we techniqually don't need it\n",
        "    x = layers.Conv2D(filters1, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    # this line is the core component of resnet, the skip connection, i.e.\n",
        "    # having a shortcut to the main path before the activation, when addition\n",
        "    # is performed on convolutional layers, the element-wise addition is performed\n",
        "    # on their feature maps, i.e. channel by channel\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdjdBiAtMgxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10cb1186-a936-4037-af98-24b372431a36"
      },
      "source": [
        "def ResNet(input_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Definition of ResNet\n",
        "    \n",
        "    References\n",
        "    ----------\n",
        "    https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n",
        "    \"\"\"\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "    \n",
        "    bn_axis = 3\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "    \n",
        "    # the commented out blocks are what's needed to build out the\n",
        "    # full ResNet50 (a ResNet with 50 layers), we won't be needing\n",
        "    # the complexity here\n",
        "    # x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    # x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    # x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    \n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    img_output = layers.Dense(n_classes, activation='softmax', name='fc' + str(n_classes))(x)\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=img_output, name='resnet')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = ResNet(input_shape, n_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 512)          0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "fc10 (Dense)                    (None, 10)           5130        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,465,226\n",
            "Trainable params: 1,455,114\n",
            "Non-trainable params: 10,112\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aND1NVqmMl5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "def888e2-f58b-4c26-f31a-7c49b0cce8cf"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=30, batch_size=32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3944 - accuracy: 0.5024\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.9790 - accuracy: 0.6560\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 0.8048 - accuracy: 0.7189\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.6794 - accuracy: 0.7629\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 58s 1ms/step - loss: 0.5823 - accuracy: 0.7979\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5002 - accuracy: 0.8249\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.4186 - accuracy: 0.8526\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 0.3525 - accuracy: 0.8761\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 56s 1ms/step - loss: 0.2960 - accuracy: 0.8948\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2478 - accuracy: 0.9134\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2099 - accuracy: 0.9257\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1834 - accuracy: 0.9353\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1577 - accuracy: 0.9452\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1416 - accuracy: 0.9503\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1301 - accuracy: 0.9545\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1159 - accuracy: 0.9594\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1074 - accuracy: 0.9626\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 54s 1ms/step - loss: 0.0976 - accuracy: 0.9652\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0948 - accuracy: 0.9666\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0903 - accuracy: 0.9683\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0815 - accuracy: 0.9714\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 54s 1ms/step - loss: 0.0796 - accuracy: 0.9724\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0753 - accuracy: 0.9740\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0703 - accuracy: 0.9758\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0653 - accuracy: 0.9773\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0658 - accuracy: 0.9772\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0652 - accuracy: 0.9773\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0577 - accuracy: 0.9797\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 54s 1ms/step - loss: 0.0557 - accuracy: 0.9810\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0552 - accuracy: 0.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiksT6-UMqwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6146c2c9-0e11-42d4-fc63-0246abbed027"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print('Loss = ' + str(loss))\n",
        "print('Test Accuracy = ' + str(accuracy))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 274us/step\n",
            "Loss = 1.2181024570465089\n",
            "Test Accuracy = 0.753000020980835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJk48N31eweq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}